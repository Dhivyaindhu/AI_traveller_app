# -*- coding: utf-8 -*-
"""Untitled143.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vsyUGX1MQjloFU7iw97HBFJq-PnpuF-v
"""

import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_gemini import ChatGemini
from langchain_core.output_parsers import StrOutputParser

# Define the prompt template
chat_template = ChatPromptTemplate.from_messages([
    ("system", "You are an AI assistant who estimates travel costs for different modes of transport from {source} to {destination}. You provide cost breakdowns and recommendations for major places."),
    ("human", "Book a flight, train, bus, or car travel from {source} to {destination}.")
])

# Gemini API Key (Use environment variables instead for security)
gemini_API_KEY = "AIzaSyCBxouxQ_5gN9ikG_RK9a6WNUotzglMVmE"

# Initialize the chat model
chat_model = ChatGemini(api_key=gemini_API_KEY, model="gemini-1.5-flash")

# Define the processing pipeline
parser = StrOutputParser()
chain = chat_template | chat_model | parser

# Streamlit UI
st.title("AI Travel Cost Estimator")

source = st.text_input("Enter Source Location:")
destination = st.text_input("Enter Destination Location:")

if st.button("Estimate Cost"):
    if source and destination:
        response = chain.invoke({"source": source, "destination": destination})
        st.write(response)
    else:
        st.warning("Please enter both source and destination.")